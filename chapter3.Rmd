# 3. Logistic Regrssion

*Describe the work you have done this week and summarize your learning.*
---

*Describe the work you have done this week and summarize your learning.*

```{R echo = FALSE, results = "hide"}
library(ggplot2)
library(tidyr)
library(dplyr)
library(boot)
```

```{R echo = FALSE}
alc <- read.csv2("data/alcohol.csv", header = TRUE)
```


Dataset is including information for 166 participant for 7 different variables.

```{R echo = FALSE}
# produce summary statistics by group
alc %>% group_by(sex,high_use) %>% summarise(count = n(), mean_grade = mean(G3))

alc %>% group_by(studytime,high_use) %>% summarise(count = n(), mean_grade = mean(G3))

alc %>% group_by(health,high_use) %>% summarise(count = n(), mean_grade = mean(G3))

alc %>% group_by(famrel,high_use) %>% summarise(count = n(), mean_grade = mean(G3))



library(ggplot2)
colnames(alc)

# initialise a plot of high_use and absences
g2 <- ggplot(alc, aes(x = high_use, y = famrel))

# define the plot as a boxplot and draw it

g2 + geom_boxplot(aes(col=sex)) + ylab("famrel") + ggtitle( "Student family relation by alcohol consumption and sex" )






# find the model with glm()
m <- glm(high_use ~ famrel + studytime + health + sex, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

# print out the coefficients of the model
coef(m)

# alc and dlyr are available 

# find the model with glm()
m <- glm(high_use ~ famrel + studytime + health + sex, data = alc, family = "binomial")

# compute odds ratios (OR)
OR <- coef(m) %>% exp

# compute confidence intervals (CI)
CI<-confint(m) %>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI)

# alc, dplyr are available

# fit the model
m <- glm(high_use ~ famrel + studytime + health + sex, data = alc, family = "binomial")

# predict() the probability of high_use
probabilities <- predict(m, type = "response")

# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# see the last ten original classes, predicted probabilities, and class predictions
select(alc, famrel , studytime , health , sex, high_use, probability, prediction) %>% tail(10)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)

# alc is available

# access dplyr and ggplot2
library(dplyr); library(ggplot2)

# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use, col = prediction))
g + geom_point()
# define the geom as points and draw the plot


# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table()%>% addmargins()

# the logistic regression model m and dataset alc with predictions are available

# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)


# the logistic regression model m and dataset alc (with predictions) are available

# define a loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)

# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]


```

